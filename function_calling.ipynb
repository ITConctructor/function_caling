{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e2a39bfe5704de0a34a9c57fb546b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1551c9f4a38342f4af538fe550416172",
              "IPY_MODEL_fb535417b3da4d4ba939c0bf68158232",
              "IPY_MODEL_fe0aab41a340444eb7e7923bd73c329f"
            ],
            "layout": "IPY_MODEL_987c2c7cc11d455693157e2ba32d5480"
          }
        },
        "1551c9f4a38342f4af538fe550416172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3903557a1514412bbda309e57844c6a9",
            "placeholder": "​",
            "style": "IPY_MODEL_3d81fa6a4d0d4925845bc11312b22225",
            "value": "100%"
          }
        },
        "fb535417b3da4d4ba939c0bf68158232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_112639d13c8347089a90037dec42b392",
            "max": 86753,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77546057b04944dea596175532a47c01",
            "value": 86753
          }
        },
        "fe0aab41a340444eb7e7923bd73c329f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5784281b34df4a2ea2114c61a9ca0425",
            "placeholder": "​",
            "style": "IPY_MODEL_08cebd403758431ba8061717bdcd7fcb",
            "value": " 86753/86753 [00:09&lt;00:00, 9012.76it/s]"
          }
        },
        "987c2c7cc11d455693157e2ba32d5480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3903557a1514412bbda309e57844c6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d81fa6a4d0d4925845bc11312b22225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "112639d13c8347089a90037dec42b392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77546057b04944dea596175532a47c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5784281b34df4a2ea2114c61a9ca0425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08cebd403758431ba8061717bdcd7fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56ec7bce565c4ecb8b3a1b6a5bfe8d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ca737ff439047149a22756cb3831734",
              "IPY_MODEL_270106328cf347b49dc11edd5fcf52d6",
              "IPY_MODEL_7f47ec70b2054bfebd71f61790c2b983"
            ],
            "layout": "IPY_MODEL_ab4c665185124bf8b2d9ea1c3f52d899"
          }
        },
        "3ca737ff439047149a22756cb3831734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e723045f3149497ba5fc35e10326a493",
            "placeholder": "​",
            "style": "IPY_MODEL_308831c534894758b244e38a288a1697",
            "value": "100%"
          }
        },
        "270106328cf347b49dc11edd5fcf52d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c1bbac0f4740dc9882ce2a82793be1",
            "max": 10868,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85db4ffb9edd47a68404b8e4e4473a8b",
            "value": 10868
          }
        },
        "7f47ec70b2054bfebd71f61790c2b983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7a6be97a2c4db6acd1cbc6b6f266fa",
            "placeholder": "​",
            "style": "IPY_MODEL_7231d26ce4404c419c480fa3c68465b9",
            "value": " 10868/10868 [00:01&lt;00:00, 6449.11it/s]"
          }
        },
        "ab4c665185124bf8b2d9ea1c3f52d899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e723045f3149497ba5fc35e10326a493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308831c534894758b244e38a288a1697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6c1bbac0f4740dc9882ce2a82793be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85db4ffb9edd47a68404b8e4e4473a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d7a6be97a2c4db6acd1cbc6b6f266fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7231d26ce4404c419c480fa3c68465b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b52ceed142ac454ead9bd78e2ef62f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a43f17de1904cc3b6f9c2b5c6354631",
              "IPY_MODEL_c0344c70ed1f4a5f943325f591326267",
              "IPY_MODEL_15f8cd8e0acc418cb59e9c9f073d72fe"
            ],
            "layout": "IPY_MODEL_6256c7b0e72e45b8a84c3d35fb236707"
          }
        },
        "3a43f17de1904cc3b6f9c2b5c6354631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d1c8a1f18134e1699bbff2079e8051b",
            "placeholder": "​",
            "style": "IPY_MODEL_6e6551f1016e4ed7963a0a2e721e447b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c0344c70ed1f4a5f943325f591326267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52ff068c7ad84c0c987cc5749bef6be1",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f5800e457ce400b9432a379351cbca9",
            "value": 33
          }
        },
        "15f8cd8e0acc418cb59e9c9f073d72fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e164f10f2344cf4ab88eb45559d921b",
            "placeholder": "​",
            "style": "IPY_MODEL_3238e0a740d94936bb73df287c08da52",
            "value": " 33/33 [01:40&lt;00:00,  3.38s/it]"
          }
        },
        "6256c7b0e72e45b8a84c3d35fb236707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1c8a1f18134e1699bbff2079e8051b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6551f1016e4ed7963a0a2e721e447b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52ff068c7ad84c0c987cc5749bef6be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5800e457ce400b9432a379351cbca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e164f10f2344cf4ab88eb45559d921b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3238e0a740d94936bb73df287c08da52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27dbcf2ea8a748769b126e92b462543f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61a7dda192a44721b17095bc2e7c914a",
              "IPY_MODEL_657bbb7e334a401ba999a9156ada8cb7",
              "IPY_MODEL_838a1ed8c0e14387800a66b2aaf5eb0b"
            ],
            "layout": "IPY_MODEL_46c685be55934a48b80eced7314ee470"
          }
        },
        "61a7dda192a44721b17095bc2e7c914a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2fcbd8a2c584cd9bf586d2069f38081",
            "placeholder": "​",
            "style": "IPY_MODEL_05954035b4ad48d3a0b15a0f49f38921",
            "value": "Training. Loss: 13.01569:  14%"
          }
        },
        "657bbb7e334a401ba999a9156ada8cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cce79c0e76d4f96aa5e7e3df3c1ef6b",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73115e434f824bd1a564a9b4d343a6b6",
            "value": 3
          }
        },
        "838a1ed8c0e14387800a66b2aaf5eb0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71fc1b2e61284b58a96e6f9eb08e7691",
            "placeholder": "​",
            "style": "IPY_MODEL_d0432c54918d4c2b88220554a627cb2c",
            "value": " 3/22 [01:15&lt;08:14, 26.05s/it]"
          }
        },
        "46c685be55934a48b80eced7314ee470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2fcbd8a2c584cd9bf586d2069f38081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05954035b4ad48d3a0b15a0f49f38921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cce79c0e76d4f96aa5e7e3df3c1ef6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73115e434f824bd1a564a9b4d343a6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71fc1b2e61284b58a96e6f9eb08e7691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0432c54918d4c2b88220554a627cb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkdSWX4pvRKc",
        "outputId": "a9eee5e7-71ce-4144-c103-8f3902b6deb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai_tools'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 58 (delta 17), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (58/58), 21.12 KiB | 7.04 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ITConctructor/function_calling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers==4.34.1 accelerate==0.24.0 sentencepiece==0.1.99 optimum==1.13.2 peft==0.5.0 bitsandbytes==0.41.2.post2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hNXgOfBQWac6",
        "outputId": "18c3e92c-f642-4327-a26b-a9d91c349936"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.34.1\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.24.0\n",
            "  Downloading accelerate-0.24.0-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting optimum==1.13.2\n",
            "  Downloading optimum-1.13.2.tar.gz (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.0/301.0 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting peft==0.5.0\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.41.2.post2\n",
            "  Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.1)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.24.0) (2.2.1+cu121)\n",
            "Collecting coloredlogs (from optimum==1.13.2)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (1.12)\n",
            "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2) (4.38.2)\n",
            "Collecting datasets (from optimum==1.13.2)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (4.10.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.1)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.24.0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.24.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting transformers[sentencepiece]>=4.26.0 (from optimum==1.13.2)\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.39.2-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.39.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.39.0-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.36.1-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.35.1-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1) (3.20.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.13.2)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->optimum==1.13.2)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (2.0.3)\n",
            "Collecting xxhash (from datasets->optimum==1.13.2)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->optimum==1.13.2)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum==1.13.2) (3.9.3)\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets (from optimum==1.13.2)\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.8,>=0.3.0 (from datasets->optimum==1.13.2)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from optimum==1.13.2)\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.13.2) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum==1.13.2) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.24.0) (2.1.5)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets->optimum==1.13.2)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum==1.13.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum==1.13.2) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum==1.13.2) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum==1.13.2) (1.16.0)\n",
            "Building wheels for collected packages: optimum\n",
            "  Building wheel for optimum (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=718e13b62fecb15631f20ca053ff2e480d642c1767343278d3f7eee4a80fb779\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\n",
            "Successfully built optimum\n",
            "Installing collected packages: bitsandbytes, xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, coloredlogs, tokenizers, nvidia-cusolver-cu12, transformers, datasets, accelerate, peft, optimum\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed accelerate-0.24.0 bitsandbytes-0.41.2.post2 coloredlogs-15.0.1 datasets-2.14.7 dill-0.3.7 huggingface-hub-0.17.3 humanfriendly-10.0 multiprocess-0.70.15 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 optimum-1.13.2 peft-0.5.0 tokenizers-0.14.1 transformers-4.34.1 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "rDlRFgQZv4JG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "rbEg867H7wIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from function_calling.src.datasets import FunctionCallingDataset\n",
        "\n",
        "model_name = \"Enoch/llama-7b-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "batch_size = 2\n",
        "train_data_params = {\n",
        "    \"tokenizer\":tokenizer,\n",
        "    \"max_input_len\":8096,\n",
        "    \"max_output_len\":8096,\n",
        "    \"is_train\":True,\n",
        "    \"size\":0.0005,\n",
        "}\n",
        "train_dataset = FunctionCallingDataset(train_data_params)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
        "\n",
        "val_data_params = {\n",
        "    \"tokenizer\":tokenizer,\n",
        "    \"max_input_len\":8096,\n",
        "    \"max_output_len\":8096,\n",
        "    \"is_train\":False,\n",
        "    \"size\":0.0005,\n",
        "}\n",
        "val_dataset = FunctionCallingDataset(val_data_params)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=val_dataset.collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "6e2a39bfe5704de0a34a9c57fb546b82",
            "1551c9f4a38342f4af538fe550416172",
            "fb535417b3da4d4ba939c0bf68158232",
            "fe0aab41a340444eb7e7923bd73c329f",
            "987c2c7cc11d455693157e2ba32d5480",
            "3903557a1514412bbda309e57844c6a9",
            "3d81fa6a4d0d4925845bc11312b22225",
            "112639d13c8347089a90037dec42b392",
            "77546057b04944dea596175532a47c01",
            "5784281b34df4a2ea2114c61a9ca0425",
            "08cebd403758431ba8061717bdcd7fcb",
            "56ec7bce565c4ecb8b3a1b6a5bfe8d5f",
            "3ca737ff439047149a22756cb3831734",
            "270106328cf347b49dc11edd5fcf52d6",
            "7f47ec70b2054bfebd71f61790c2b983",
            "ab4c665185124bf8b2d9ea1c3f52d899",
            "e723045f3149497ba5fc35e10326a493",
            "308831c534894758b244e38a288a1697",
            "a6c1bbac0f4740dc9882ce2a82793be1",
            "85db4ffb9edd47a68404b8e4e4473a8b",
            "7d7a6be97a2c4db6acd1cbc6b6f266fa",
            "7231d26ce4404c419c480fa3c68465b9"
          ]
        },
        "collapsed": true,
        "id": "5r08D8F0v_71",
        "outputId": "b7314319-26b1-44fe-df1a-891b2e432747"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86753 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e2a39bfe5704de0a34a9c57fb546b82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10868 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56ec7bce565c4ecb8b3a1b6a5bfe8d5f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from function_calling.src.models import PeftLLM\n",
        "from function_calling.src.trainer import Trainer\n",
        "\n",
        "trainer_args = {\n",
        "    \"train_dataloader\":train_dataloader,\n",
        "    \"val_dataloader\":val_dataloader,\n",
        "    \"score\":None,\n",
        "    \"train_score_computing_frequency\":1,\n",
        "    \"optimizer\":torch.optim.AdamW,\n",
        "    \"optimizer_args\":{\"lr\":3e-4},\n",
        "    \"scheduler\":None,\n",
        "    \"scheduler_args\":None,\n",
        "    \"freezer\":None,\n",
        "    \"freezer_args\":None,\n",
        "    \"training_controller\":None,\n",
        "    \"n_epochs\":1,\n",
        "    \"device\":\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    \"backup_path\":\"/content/drive/MyDrive/ml_studcamp/fc_v1.pt\",\n",
        "    \"show_outputs\":True,\n",
        "    \"show_outputs_every\":1,\n",
        "    \"n_outputs\":1,\n",
        "}\n",
        "\n",
        "trainer = Trainer(trainer_args)\n",
        "\n",
        "model_args = {\n",
        "    \"model_name\":model_name,\n",
        "    \"weights_dtype\":torch.float16,\n",
        "    \"load_in_4bit\":True\n",
        "}\n",
        "model = PeftLLM(model_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b52ceed142ac454ead9bd78e2ef62f66",
            "3a43f17de1904cc3b6f9c2b5c6354631",
            "c0344c70ed1f4a5f943325f591326267",
            "15f8cd8e0acc418cb59e9c9f073d72fe",
            "6256c7b0e72e45b8a84c3d35fb236707",
            "4d1c8a1f18134e1699bbff2079e8051b",
            "6e6551f1016e4ed7963a0a2e721e447b",
            "52ff068c7ad84c0c987cc5749bef6be1",
            "6f5800e457ce400b9432a379351cbca9",
            "9e164f10f2344cf4ab88eb45559d921b",
            "3238e0a740d94936bb73df287c08da52"
          ]
        },
        "collapsed": true,
        "id": "bk1ewulUEzfi",
        "outputId": "b9400313-06a5-45aa-930a-8d5a9923cc6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b52ceed142ac454ead9bd78e2ef62f66"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "27dbcf2ea8a748769b126e92b462543f",
            "61a7dda192a44721b17095bc2e7c914a",
            "657bbb7e334a401ba999a9156ada8cb7",
            "838a1ed8c0e14387800a66b2aaf5eb0b",
            "46c685be55934a48b80eced7314ee470",
            "e2fcbd8a2c584cd9bf586d2069f38081",
            "05954035b4ad48d3a0b15a0f49f38921",
            "8cce79c0e76d4f96aa5e7e3df3c1ef6b",
            "73115e434f824bd1a564a9b4d343a6b6",
            "71fc1b2e61284b58a96e6f9eb08e7691",
            "d0432c54918d4c2b88220554a627cb2c"
          ]
        },
        "id": "SJJUk_3rivEU",
        "outputId": "35bc55a3-07d7-4e9d-8124-1a0b8e63f1f7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27dbcf2ea8a748769b126e92b462543f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "print(\"Total parameters (excluding quantization):\", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tSF-O_zvqIN",
        "outputId": "9a23cc16-b962-49ad-c90e-bf07a109a148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 8388608\n",
            "Total parameters (excluding quantization): 3508801536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classes"
      ],
      "metadata": {
        "id": "wQUesGgC09VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import peft\n",
        "from peft import PeftModel, PeftConfig, LoraConfig\n",
        "from transformers import AutoModelForCausalLM\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PeftLLM(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        self.model_name = params[\"model_name\"]\n",
        "        self.weights_dtype = params.get(\"weights_dtype\", torch.float16)\n",
        "        load_in_4bit = params.get(\"load_in_4bit\", False)\n",
        "        self.base_model = AutoModelForCausalLM.from_pretrained(self.model_name, device_map='auto',\n",
        "        low_cpu_mem_usage=True, offload_state_dict=True, torch_dtype=self.weights_dtype, load_in_4bit=load_in_4bit)\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.base_model.gradient_checkpointing_enable()\n",
        "        self.base_model.enable_input_require_grads()\n",
        "        self.tokenizer = params.get(\"tokenizer\", AutoTokenizer.from_pretrained(self.model_name))\n",
        "        if self.tokenizer.pad_token_id is None:\n",
        "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
        "\n",
        "        self.peft_config = LoraConfig(\n",
        "            r=16,\n",
        "            target_modules=[\"q_proj\", \"v_proj\"],\n",
        "            task_type=peft.TaskType.CAUSAL_LM,\n",
        "            lora_alpha=32,\n",
        "            lora_dropout=0.05\n",
        "        )\n",
        "        self.peft_model = peft.get_peft_model(self.base_model, self.peft_config)\n",
        "\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, batch):\n",
        "        inp = {\"input_ids\":batch[\"input_text\"]['input_ids'], \"attention_mask\":batch[\"input_text\"]['attention_mask']}\n",
        "        logits = self.peft_model(**inp).loss[\"logits\"].permute(0, 2, 1)\n",
        "\n",
        "        out = batch[\"output_text\"]['input_ids']\n",
        "        loss = self.loss(logits, inp[\"input_ids\"])\n",
        "        return loss\n",
        "    def predict(self, batch):\n",
        "        inp = {\"input_ids\":batch[\"input_text\"]['input_ids'], \"attention_mask\":batch[\"input_text\"]['attention_mask']}\n",
        "        with torch.no_grad():\n",
        "            generated_ids = self.base_model.generate(**inp)\n",
        "        out = {\n",
        "            \"out_ids\":generated_ids\n",
        "        }\n",
        "        return out\n",
        "    def show_outputs(self, batch):\n",
        "        inp = {\"input_ids\":batch[\"input_text\"]['input_ids'], \"attention_mask\":batch[\"input_text\"]['attention_mask']}\n",
        "        generated_ids = self.base_model.generate(**inp)\n",
        "        generated_sentences = self.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "        print(\"Generated sentence:\")\n",
        "        for s in generated_sentences:\n",
        "            print(s)\n",
        "        return"
      ],
      "metadata": {
        "id": "AzTvIl1ZLw1k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Trainer():\n",
        "  def __init__(self, params):\n",
        "    torch.manual_seed(42)\n",
        "    self.train_dataloader = params[\"train_dataloader\"]\n",
        "    self.val_dataloader = params[\"val_dataloader\"]\n",
        "    self.score = params[\"score\"]\n",
        "    self.train_score_computing_frequency = params.get(\"train_score_computing_frequency\", 1)\n",
        "    self.optimizer = params[\"optimizer\"]\n",
        "    self.optimizer_args = params[\"optimizer_args\"]\n",
        "    self.scheduler = params.get(\"scheduler\", None)\n",
        "    self.scheduler_args = params.get(\"scheduler_args\", None)\n",
        "    self.freezer = params.get(\"freezer\", None)\n",
        "    self.freezer_args = params.get(\"freezer_args\", None)\n",
        "    self.training_controller = params.get(\"training_controller\", None)\n",
        "    self.training_controller_params = params.get(\"training_controller_params\", None)\n",
        "    self.show_outputs = params.get(\"show_outputs\", False)\n",
        "    self.show_outputs_every = params.get(\"show_outputs_every\", 1)\n",
        "    self.n_outputs = params.get(\"n_outputs\", 2)\n",
        "    self.n_epochs = params[\"n_epochs\"]\n",
        "    self.device = params[\"device\"]\n",
        "    self.backup_path = params.get(\"backup_path\", None)\n",
        "    self.history = {\n",
        "        \"train_loss\":[],\n",
        "        \"train_score\":[],\n",
        "        \"val_loss\":[],\n",
        "        \"val_score\":[]\n",
        "    }\n",
        "  def train(self, model, verbose=True):\n",
        "    model = model.to(self.device)\n",
        "    optimizer = self.optimizer(model.parameters(), **self.optimizer_args)\n",
        "    scheduler = None\n",
        "    if self.scheduler != None and self.scheduler_args != None:\n",
        "      scheduler = self.scheduler(optimizer, **self.scheduler_args)\n",
        "    freezer = None\n",
        "    if self.freezer != None and self.freezer_args != None:\n",
        "      freezer = self.freezer(model, **self.freezer_args)\n",
        "\n",
        "    losses = {\n",
        "      \"train\":[],\n",
        "      \"val\":[]\n",
        "    }\n",
        "    scores = {\n",
        "      \"train\":[],\n",
        "      \"val\":[]\n",
        "    }\n",
        "\n",
        "    if self.training_controller != None:\n",
        "      self.training_controller_params[\"model\"] = model\n",
        "      self.training_controller_params[\"optimizer\"] = optimizer\n",
        "      self.training_controller_params[\"scheduler\"] = scheduler\n",
        "      self.training_controller_params[\"losses\"] = losses\n",
        "      self.training_controller_params[\"scores\"] = scores\n",
        "      controller = self.training_controller(self.training_controller_params)\n",
        "\n",
        "    for epoch in range(self.n_epochs):\n",
        "      #Training\n",
        "      model.train()\n",
        "      if freezer != None:\n",
        "        freezer.step()\n",
        "      train_loss = 0\n",
        "      train_score = 0\n",
        "      steps = 0\n",
        "      train_pbar = tqdm(self.train_dataloader, desc=\"Training\")\n",
        "\n",
        "      local_losses = []\n",
        "      local_scores = []\n",
        "      losses[\"train\"].append(local_losses)\n",
        "      scores[\"train\"].append(local_scores)\n",
        "      for batch in train_pbar:\n",
        "        optimizer.zero_grad()\n",
        "        train_batch = self.device_dict(batch[\"train\"])\n",
        "        loss = model(train_batch)\n",
        "        loss.backward()\n",
        "        local_losses.append(loss.item())\n",
        "\n",
        "        val_batch = self.device_dict(batch[\"val\"])\n",
        "        labels = self.device_dict(batch[\"labels\"])\n",
        "\n",
        "        if self.score != None:\n",
        "          preds = model.predict(val_batch)\n",
        "          if steps % self.train_score_computing_frequency == 0:\n",
        "            score = self.score(preds, labels)\n",
        "            local_scores.append(score)\n",
        "\n",
        "        if self.training_controller != None:\n",
        "          controller.batch_update()\n",
        "        optimizer.step()\n",
        "\n",
        "        display_loss = round(loss.item(), 5)\n",
        "        train_pbar.set_description(\"Training. Loss: %s\" % display_loss)\n",
        "        steps += 1\n",
        "\n",
        "\n",
        "\n",
        "      train_loss = sum(local_losses)/len(local_losses)\n",
        "      if len(local_scores) > 0:\n",
        "        train_score = sum(local_scores)/len(local_scores)\n",
        "\n",
        "      if scheduler != None:\n",
        "        scheduler.step()\n",
        "\n",
        "      #Validation\n",
        "      model.eval()\n",
        "      val_loss = 0\n",
        "      val_score = 0\n",
        "      local_losses = []\n",
        "      local_scores = []\n",
        "      losses[\"val\"].append(local_losses)\n",
        "      scores[\"val\"].append(local_scores)\n",
        "      for batch in tqdm(self.val_dataloader, desc=\"Validation\"):\n",
        "        with torch.no_grad():\n",
        "          train_batch = self.device_dict(batch[\"train\"])\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss = model(train_batch)\n",
        "          local_losses.append(loss.item())\n",
        "          val_loss += loss.item()/len(self.val_dataloader)\n",
        "\n",
        "          val_batch = train_batch = self.device_dict(batch[\"val\"])\n",
        "          labels = train_batch = self.device_dict(batch[\"labels\"])\n",
        "\n",
        "          if self.score != None:\n",
        "            preds = model.predict(val_batch)\n",
        "            score = self.score(preds, labels)\n",
        "            local_scores.append(score)\n",
        "            val_score += score/(len(self.val_dataloader))\n",
        "\n",
        "      self.history[\"train_loss\"].append(train_loss)\n",
        "      self.history[\"train_score\"].append(train_score)\n",
        "      self.history[\"val_loss\"].append(val_loss)\n",
        "      self.history[\"val_score\"].append(val_score)\n",
        "\n",
        "      if self.training_controller != None:\n",
        "          controller.epoch_update()\n",
        "\n",
        "      if verbose:\n",
        "        print(f\"Epoch {epoch+1}. Train loss: {train_loss}, val loss: {val_loss}, train score: {train_score}, val score: {val_score}\")\n",
        "\n",
        "      if self.show_outputs == True and epoch % self.show_outputs_every == 0:\n",
        "        self.show_outputs_fn(model, self.val_dataloader)\n",
        "\n",
        "      if self.backup_path != None:\n",
        "        torch.save(model, self.backup_path)\n",
        "      self.save_history()\n",
        "\n",
        "  def save_history(self):\n",
        "    plt.ioff()\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(range(len(self.history[\"train_loss\"])), self.history[\"train_loss\"], label=\"Train\")\n",
        "    ax.plot(range(len(self.history[\"val_loss\"])), self.history[\"val_loss\"], label=\"Val\")\n",
        "    fig.savefig(\"Losses.pdf\")\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(range(len(self.history[\"train_score\"])), self.history[\"train_score\"], label=\"Train\")\n",
        "    ax.plot(range(len(self.history[\"val_score\"])), self.history[\"val_score\"], label=\"Val\")\n",
        "    fig.savefig(\"Scores.pdf\")\n",
        "\n",
        "  def plot_lr_schedule(self):\n",
        "    steps = [self.optimizer_args[\"lr\"]]\n",
        "    if self.scheduler == None or self.scheduler_args == None:\n",
        "      steps = [self.optimizer_args[\"lr\"] for i in range(self.n_epochs)]\n",
        "    else:\n",
        "      dummyModel = nn.Linear(10, 10)\n",
        "      dummyOptimizer = self.optimizer(dummyModel.parameters(), **self.optimizer_args)\n",
        "      scheduler = scheduler = self.scheduler(dummyOptimizer, **self.scheduler_args)\n",
        "      for i in range(1, self.n_epochs):\n",
        "        dummyOptimizer.step()\n",
        "        scheduler.step()\n",
        "        lr = scheduler.get_last_lr()[0]\n",
        "        steps.append(lr)\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(range(len(steps)), steps)\n",
        "    plt.show()\n",
        "  def device_dict(self, dictionary):\n",
        "    for k in dictionary.keys():\n",
        "      if type(dictionary[k]) == type({}):\n",
        "        dictionary[k] = self.device_dict(dictionary[k])\n",
        "      else:\n",
        "        dictionary[k] = dictionary[k].to(self.device)\n",
        "    return dictionary\n",
        "  def show_outputs_fn(self, model, dataloader):\n",
        "    dataset = dataloader.dataset\n",
        "    collate_fn = dataloader.collate_fn\n",
        "    indexes = random.sample(range(len(dataset)), self.n_outputs)\n",
        "    inputs = [dataset[i] for i in indexes]\n",
        "    processed = collate_fn(inputs)\n",
        "    batch = self.device_dict(processed)\n",
        "    print(\"Output samples:\\n\")\n",
        "    dataset.show_samples(indexes)\n",
        "    model.show_outputs(batch[\"val\"])\n",
        ""
      ],
      "metadata": {
        "id": "-X2aoBpkTty3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "class FunctionCallingDataset(Dataset):\n",
        "    def __init__(self, params):\n",
        "        self.max_input_len = params[\"max_input_len\"]\n",
        "        self.max_output_len = params[\"max_output_len\"]\n",
        "        self.tokenizer = params[\"tokenizer\"]\n",
        "        self.train = params.get(\"is_train\", True)\n",
        "        self.size = params.get(\"size\",1)\n",
        "\n",
        "        self.SYSTEM_PROMPT = (\n",
        "            \"You are a helpful assistant with function-calling supported. You are provided with function signatures within <TOOLS></TOOLS> XML tags. \"\n",
        "            \"You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. \"\n",
        "            \"Here are the available tools:\\n\"\n",
        "            \"<TOOLS>\\n\"\n",
        "            \"{tools}\\n\"\n",
        "            \"</TOOLS>\\n\\n\"\n",
        "            \"For each function call, return a JSON object with the function name and arguments within <TOOL_CALL></TOOL_CALL> XML tags as follows:\\n\"\n",
        "            \"<TOOL_CALL>\\n\"\n",
        "            \"{{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-dict>}}\\n\"\n",
        "            \"</TOOL_CALL>\"\n",
        "            \"You will get function call result within <TOOL_RESPONSE></TOOL_RESPONSE> XML tags. \"\n",
        "            \"Answer user query based on the result.\"\n",
        "        )\n",
        "\n",
        "        self.S_B, self.S_E = \"<s>\", \"</s>\"\n",
        "        self.INST_B, self.INST_E = \"[INST] \", \" [/INST] \"\n",
        "        self.SYS_B, self.SYS_E = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "        self.TOOL_CALL_B, self.TOOL_CALL_E = \"<TOOL_CALL>\\n\", \"\\n</TOOL_CALL>\\n\\n\"\n",
        "        self.TOOL_RESPONSE_B, self.TOOL_RESPONSE_E = \"<TOOL_RESPONSE>\\n\", \"\\n</TOOL_RESPONSE>\\n\\n\"\n",
        "\n",
        "        hf_dataset = load_dataset(\"korotkov/glaive-function-calling-v2-parsed\")\n",
        "\n",
        "        # Convert dataset to another format\n",
        "        dataset_key = \"train\" if self.train else \"test\"\n",
        "        self.dataset = []\n",
        "        self.prompts = []\n",
        "        self.answers = []\n",
        "        for row in tqdm(hf_dataset[dataset_key]):\n",
        "            messages = json.loads(row[\"messages\"])\n",
        "            functions = json.loads(row[\"functions\"])\n",
        "            all_text, prompt, answer = self.llama_convert(messages, functions)\n",
        "            self.dataset.append(all_text)\n",
        "            self.prompts.append(prompt)\n",
        "            self.answers.append(answer)\n",
        "        self.dataset = self.dataset[:int(len(self.dataset)*self.size)]\n",
        "        self.prompts = self.prompts[:int(len(self.prompts)*self.size)]\n",
        "        self.answers = self.answers[:int(len(self.answers)*self.size)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    def __getitem__(self, ind):\n",
        "        text = self.dataset[ind]\n",
        "        val_text = self.prompts[ind]\n",
        "        out_text = self.answers[ind]\n",
        "        item = {\n",
        "            \"train\":{\n",
        "                \"input_text\":text,\n",
        "                \"output_text\":text\n",
        "            },\n",
        "            \"val\":{\n",
        "                \"input_text\":val_text\n",
        "            },\n",
        "            \"labels\":{\n",
        "                \"output_text\":out_text\n",
        "            }\n",
        "        }\n",
        "        return item\n",
        "    def show_samples(self, indexes):\n",
        "        texts = [self.prompts[ind] for ind in indexes]\n",
        "        print(\"Prompts:\")\n",
        "        for t in texts:\n",
        "          print(t)\n",
        "        return texts\n",
        "    def llama_convert(self, messages, functions):\n",
        "      tools = \",\\n\".join([json.dumps(function, indent=4) for function in functions])\n",
        "      messages[0][\"content\"] = self.SYSTEM_PROMPT.format(tools=tools)\n",
        "\n",
        "      messages_string = [self.S_B, self.INST_B]\n",
        "      prompts_string = [self.S_B, self.INST_B]\n",
        "      answers_string = []\n",
        "      for message in messages:\n",
        "          if message[\"role\"] == \"system\":\n",
        "              messages_string.append(self.SYS_B)\n",
        "              messages_string.append(message[\"content\"])\n",
        "              messages_string.append(self.SYS_E)\n",
        "\n",
        "              prompts_string.append(self.SYS_B)\n",
        "              prompts_string.append(message[\"content\"])\n",
        "              prompts_string.append(self.SYS_E)\n",
        "          elif message[\"role\"] == \"user\":\n",
        "              messages_string.append(message[\"content\"])\n",
        "              messages_string.append(self.INST_E)\n",
        "\n",
        "              prompts_string.append(message[\"content\"])\n",
        "              prompts_string.append(self.INST_E)\n",
        "          elif message[\"role\"] == \"assistant\":\n",
        "              messages_string.append(message[\"content\"])\n",
        "              messages_string.append(self.S_E)\n",
        "\n",
        "              answers_string.append(message[\"content\"])\n",
        "              answers_string.append(self.S_E)\n",
        "          elif message[\"role\"] == \"function_call\":\n",
        "              messages_string.append(self.TOOL_CALL_B)\n",
        "              messages_string.append(message[\"content\"])\n",
        "              messages_string.append(self.TOOL_CALL_E)\n",
        "\n",
        "              answers_string.append(self.TOOL_CALL_B)\n",
        "              answers_string.append(message[\"content\"])\n",
        "              answers_string.append(self.TOOL_CALL_E)\n",
        "          elif message[\"role\"] == \"function_response\":\n",
        "              messages_string.append(self.TOOL_RESPONSE_B)\n",
        "              messages_string.append(message[\"content\"])\n",
        "              messages_string.append(self.TOOL_RESPONSE_E)\n",
        "\n",
        "              answers_string.append(self.TOOL_RESPONSE_B)\n",
        "              answers_string.append(message[\"content\"])\n",
        "              answers_string.append(self.TOOL_RESPONSE_E)\n",
        "\n",
        "      all_text = \"\".join(messages_string)\n",
        "      spl = all_text.rsplit(self.INST_E, 1)\n",
        "      prompt = spl[0] + self.INST_E\n",
        "      answer = spl[1]\n",
        "      return all_text, prompt, answer\n",
        "    def collate_fn(self, batch):\n",
        "        texts = [\"input_text\", \"output_text\"]\n",
        "        lens = [self.max_input_len, self.max_output_len]\n",
        "\n",
        "        new_batch = {\n",
        "            \"train\":{\n",
        "                \"input_text\":None,\n",
        "                \"output_text\":None\n",
        "            },\n",
        "            \"val\":{\n",
        "                \"input_text\":None\n",
        "            },\n",
        "            \"labels\":{\n",
        "                \"output_text\":None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for t, l in zip(texts, lens):\n",
        "            max_batch_len = 0\n",
        "            texts = [b[\"train\"][t] for b in batch]\n",
        "            for text in texts:\n",
        "                tokenized = self.tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "                length = tokenized[\"input_ids\"].shape[1]\n",
        "                if length > max_batch_len:\n",
        "                    max_batch_len = length\n",
        "            max_batch_len = min(max_batch_len, l)\n",
        "            for k in new_batch.keys():\n",
        "                tokenized = self.tokenizer(texts, return_tensors=\"pt\", max_length=max_batch_len, padding=\"max_length\", truncation=True)\n",
        "                if t == \"input_text\":\n",
        "                  tokenized[\"input_ids\"] = tokenized[\"input_ids\"][:,:-1]\n",
        "                  tokenized[\"attention_mask\"] = tokenized[\"attention_mask\"][:,:-1]\n",
        "                else:\n",
        "                  tokenized[\"input_ids\"] = tokenized[\"input_ids\"][:,1:]\n",
        "                  tokenized[\"attention_mask\"] = tokenized[\"attention_mask\"][:,1:]\n",
        "                if t in new_batch[k]:\n",
        "                    if k != \"train\":\n",
        "                      true_texts = [b[k][t] for b in batch]\n",
        "                      tokenized = self.tokenizer(true_texts, padding=True, return_tensors=\"pt\")\n",
        "                    new_batch[k][t] = tokenized\n",
        "\n",
        "        return new_batch"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4-w9SBdC7y8Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "08rU1XFGjOMA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}